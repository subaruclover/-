<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>多智能体强化学习 &mdash; MARL 0.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/style.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/vega@5.20.2"></script>
        <script src="https://cdn.jsdelivr.net/npm/vega-lite@5.1.0"></script>
        <script src="https://cdn.jsdelivr.net/npm/vega-embed@6.17.0"></script>
        <script src="_static/js/copybutton.js"></script>
        <script src="_static/js/benchmark.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="强化学习概论" href="usage.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html">
            <img src="_static/logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.1.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="usage.html">强化学习概论</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">多智能体强化学习</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#intro">现有的(多智能体)强化学习中文社区教材和讲义</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#rlchina">1. RLChina 强化学习社区</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ai">2. 伯禹AI (由上海交通大学张伟楠教授团队出品)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#marl-material3">3. 西湖大学 (课本、视频) 赵世钰教授团队，飞行器控制领域</a></li>
<li class="toctree-l3"><a class="reference internal" href="#marl-material4">4. 其他相关课程和资料</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id5">课程设计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#outline">课程设计outline</a></li>
<li class="toctree-l3"><a class="reference internal" href="#marl-concept">MARL Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="#classification">Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="#current-solutions-based-on-different-criteria">Current solutions (based on different criteria)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#algorithms-introduction-and-code-review">Algorithms introduction and code review</a></li>
<li class="toctree-l3"><a class="reference internal" href="#connect-with-ai-arena-platform">Connect with AI Arena platform</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MARL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>多智能体强化学习</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/intro.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="id1">
<h1>多智能体强化学习<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h1>
<section id="intro">
<span id="id2"></span><h2>现有的(多智能体)强化学习中文社区教材和讲义<a class="headerlink" href="#intro" title="Permalink to this heading">¶</a></h2>
<section id="rlchina">
<span id="marl-material"></span><h3>1. RLChina 强化学习社区<a class="headerlink" href="#rlchina" title="Permalink to this heading">¶</a></h3>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">链接</span></code>：<a class="reference external" href="http://rlchina.org/">http://rlchina.org/</a></p>
<p>UCL 汪军教授《Multi-agent AI》课程（中文字幕）Bilibili：</p>
<p><a class="reference external" href="https://www.bilibili.com/video/BV1fz4y1S72S?p=1&amp;vd_source=38b5017372fe991e5b7e30cb941ee82c">Bilibili 视频链接</a></p>
<p>Multi-agent AI 课程简介 (侧重多智能体)：</p>
<p>该课程主要介绍人工智能（AI）的一个子领域——多智能体机器学习。多智能体学习在多个领域中均有体现，多智能体间不仅能与环境相互作用，而且彼此相互作用。因此，相关应用也越来越多，比如 <cite>无人机群</cite> 的控制和仓库机器人的合作，以及分布式传感器网络/交通的优化以及机器竞标。该课程将机器学习的研究与博弈论和经济学的研究相结合，包括 <code class="docutils literal notranslate"><span class="pre">博弈论</span></code> 、 <code class="docutils literal notranslate"><span class="pre">拍卖理论</span></code> 、 <code class="docutils literal notranslate"><span class="pre">算法机制设计</span></code> 、 <code class="docutils literal notranslate"><span class="pre">多智能体（深度）强化学习</span></code> 等主题。同时还将覆盖和讨论相关的实际应用，包括在线广告、在线拍卖、生成模型的对抗训练、机器人规划以及玩在线游戏的智能体。</p>
<p>Multi-agent AI 课程大纲：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>1. 第0讲 引言
2. 第1.1讲 博弈论的基本概念
3. 第1.2讲 纯策略纳什均衡
4. 第1.3讲 混合策略纳什均衡
5. 第1.4讲 纳什均衡的存在性证明
6. 第1.5讲 古诺双寡头模型
7. 第2.1讲 重复博弈
8. 第2.2讲 扩展形式博弈
9. 第2.3讲 势博弈上
10. 第2.4讲 势博弈下
11. 第3.1讲 零和博弈及纳什均衡计算 *
12. 第3.2讲 极大极小博弈
13. 第3.3讲 纳什均衡的线性规划解法
14. 第3.4讲 线性互补性问题
15. 第3.5讲 Lemke-Howson算法求解线性互补性问题
16. 第4.1讲 贝叶斯博弈 *
17. 第4.2讲 在线拍卖的设置与步骤
18. 第4.3讲 拍卖模式：一口价拍卖与密封式拍卖
19. 第4.4讲 竞价策略与纳什均衡上
20. 第4.5讲 竞价策略与纳什均衡下
21. 第5.1讲 深度学习基础 *
22. 第5.2讲 词嵌入
23. 第5.3讲 深度神经网路层 *
24. 第5.4讲 卷积神经网路 *
25. 第5.5讲 循环神经网络 *
26. 第5.6讲 网络信息搜索
27. 第5.7讲 表征学习
28. 第6.1讲 强化学习基础 *
29. 第6.2讲 model-based方法 *
30. 第6.3讲 model-free方法 *
31. 第7.1讲 多智能体强化学习介绍及基本概念 *
32. 第7.2讲 值迭代与策略迭代 *
33. 第7.3讲 均衡学习
34. 第7.4讲 最佳对策
35. 第8.1讲 策略方法
36. 第8.2讲 策略方法学习理论介绍
37. 第8.3讲 理论分析
38. 第9.1讲 采用策略预测的IGA
39. 第9.2讲 类动态系统的梯度提升优化
40. 第9.3讲 不同博弈中的学习
41. 第9.4讲 虚拟模拟
42. 第9.5讲 平滑虚拟博弈
43. 第9.6讲 理性学习
44. 第9.7讲 演化博弈论
45. 第9.8讲 模仿者动态理论
46. 第10.1讲 相关均衡与无悔学习
47. 第10.2讲 多智能体评价 *
48. 第10.3讲 多智能体强化学习：进阶主题 *
</pre></div>
</div>
</div></blockquote>
</section>
<section id="ai">
<span id="marl-material2"></span><h3>2. 伯禹AI (由上海交通大学张伟楠教授团队出品)<a class="headerlink" href="#ai" title="Permalink to this heading">¶</a></h3>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">链接</span></code>：<a class="reference external" href="https://www.boyuai.com/elites/">https://www.boyuai.com/elites/</a></p>
<p>强化学习课程：<a class="reference external" href="https://www.boyuai.com/elites/course/xVqhU42F5IDky94x">https://www.boyuai.com/elites/course/xVqhU42F5IDky94x</a></p>
<p>伯禹AI 强化学习课程大纲 (每小节后有课后习题/代码实践)：</p>
<ol class="arabic">
<li><p><code class="docutils literal notranslate"><span class="pre">模块一</span> <span class="pre">/</span> <span class="pre">强化学习基础</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>- 多臂老虎机 (Multi-armed bandits problem) /
- 马尔科夫决策过程 (Markov Decision Process (MDP)) /
- 基于动态规划的强化学习 (Dynamic Programing (DP)) 「代码实践」*
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">模块二</span> <span class="pre">/</span> <span class="pre">模型无关强化学习方法</span> <span class="pre">(model-free</span> <span class="pre">RL)</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>- 蒙特卡罗方法 (Monte Carlo (MC) method) /
- 蒙特卡罗价值预测 (MC value based evaluation (Prediction)) /
- 重要性采样 (Importance sampling) /
- 时序差分学习 (Temporal difference (TD) learning) /
- SARSA 「代码实践」* /
- Q-learning 「代码实践」/
- 多步自助法 (n-step) /
- 参数化值函数近似 (Function approximation) /
- 状态值函数与状态-动作值函数 (State value function and state-action value function)/
- 策略梯度方法 (Policy gradiant (PG) method) /
- Actor-Critic
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">模块三</span> <span class="pre">/</span> <span class="pre">基于模型的强化学习方法</span> <span class="pre">(model-based</span> <span class="pre">RL)</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>- 代码实践：策略梯度
- 规划与学习之入门算法与介绍 (Policy Programing) /
- 规划与学习之采样方法 (Sampling) /
- 规划与学习之决策时规划 (Policy)
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">模块四</span> <span class="pre">/</span> <span class="pre">深度强化学习</span> <span class="pre">(Deep</span> <span class="pre">RL)</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>- 深度强化学习介绍 (Deep Reinforcement Learning) /
- 深度Q网络 (Deep-Q network (DQN)) 「代码实践」* /
- A3C (Asynchronous Advantage Actor-Critic) 「代码实践」* /
- 信任域策略优化 (Trust region policy optimization (TRPO))/
- 邻近策略优化 (Proximal policy optimization (PPO)) 「代码实践」* /
- 确定性策略梯度 (Deterministic Policy Gradient (DPG)) /
- 深度确定性策略梯度 (Deep Deterministic Policy Gradient (DDPG))
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">模块五</span> <span class="pre">/</span> <span class="pre">强化学习进阶</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>- 概率图强化学习：Soft Q-learning &amp; Soft Actor-Critic /
- 模仿学习 (Imitation learning) /
- 行为克隆 /
- 逆强化学习 (Inverse RL) /
- 生成对抗模仿学习 (Generative adversarial imitation learning (GAIL)) /
- 参数化动作空间 /
- 模型预测控制 /
- 基于模型的策略优化 /
- 目标导向的强化学习 /
# 多智能体强化学习 (MARL) /
- 离线强化学习 (offline RL)
</pre></div>
</div>
</li>
</ol>
</div></blockquote>
</section>
<section id="marl-material3">
<span id="id3"></span><h3>3. 西湖大学 (课本、视频) 赵世钰教授团队，飞行器控制领域<a class="headerlink" href="#marl-material3" title="Permalink to this heading">¶</a></h3>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">书籍链接</span></code> <a class="reference external" href="https://github.com/MathFoundationRL/Book-Mathmatical-Foundation-of-Reinforcement-Learning">https://github.com/MathFoundationRL/Book-Mathmatical-Foundation-of-Reinforcement-Learning</a></p>
<p>课程视频（中文）
Bilibili <a class="reference external" href="https://space.bilibili.com/2044042934">https://space.bilibili.com/2044042934</a>
Youtube频道 <a class="reference external" href="https://www.youtube.com/channel/UCztGtS5YYiNv8x3pj9hLVgg/playlists">https://www.youtube.com/channel/UCztGtS5YYiNv8x3pj9hLVgg/playlists</a></p>
</div></blockquote>
</section>
<section id="marl-material4">
<span id="id4"></span><h3>4. 其他相关课程和资料<a class="headerlink" href="#marl-material4" title="Permalink to this heading">¶</a></h3>
<blockquote>
<div><p>伯克利+上海交通大学 RL</p>
<p>AAAI-22 中科院自动化所-飞行器智能技术，多智能体AI团队
Concentration network for Reinforcement Learning of Large-scale Multi-agent systems</p>
</div></blockquote>
<p>参考文献（MARL survey）list</p>
<blockquote>
<div><p>RL 溯源，分支 -&gt; control theory, neuroscience (old paper)</p>
</div></blockquote>
</section>
</section>
<section id="id5">
<h2>课程设计<a class="headerlink" href="#id5" title="Permalink to this heading">¶</a></h2>
<p>当前在强化学习领域中，对MARL这一块目前没有很系统的介绍，最初RL用于单个个体 (single agent) 在和环境和互动中习得如何做决策，学习达到奖励的策略。现在大量的关注涌向了多智能体的领域，状态空间，状态-行为空间急速上升，其他智能体和环境的仅部分可观测特性使得适用于单智能体的算法在多智能体的情况下往往不再适用。我们可以按照任务的标准或者模型的标准来划分各种多智能体的算法分类。</p>
<p>分类</p>
<p>现有的解决方案</p>
<p>实例讲解（代码实践）</p>
<section id="outline">
<span id="marl-outline"></span><h3>课程设计outline<a class="headerlink" href="#outline" title="Permalink to this heading">¶</a></h3>
</section>
<section id="marl-concept">
<h3>MARL Concept<a class="headerlink" href="#marl-concept" title="Permalink to this heading">¶</a></h3>
</section>
<section id="classification">
<h3>Classification<a class="headerlink" href="#classification" title="Permalink to this heading">¶</a></h3>
</section>
<section id="current-solutions-based-on-different-criteria">
<h3>Current solutions (based on different criteria)<a class="headerlink" href="#current-solutions-based-on-different-criteria" title="Permalink to this heading">¶</a></h3>
<blockquote>
<div><p>–Cooperative</p>
<p class="attribution">—Model</p>
</div></blockquote>
</section>
<section id="algorithms-introduction-and-code-review">
<h3>Algorithms introduction and code review<a class="headerlink" href="#algorithms-introduction-and-code-review" title="Permalink to this heading">¶</a></h3>
</section>
<section id="connect-with-ai-arena-platform">
<h3>Connect with AI Arena platform<a class="headerlink" href="#connect-with-ai-arena-platform" title="Permalink to this heading">¶</a></h3>
<p>课后习题（后面设计）</p>
<p>实例讲解</p>
<p>助教答疑（团队）</p>
<p>课件模板</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>要明确这不是一门零基础课</p>
<p>是进阶课</p>
<p>但是也不担心学不明白</p>
<p>时间：以年为单位</p>
<p>参考文献: <a class="reference external" href="https://github.com/subaruclover/MARL_AI_outline/tree/main/docs/source/_static/references">https://github.com/subaruclover/MARL_AI_outline/tree/main/docs/source/_static/references</a></p>
<p><code class="docutils literal notranslate"><span class="pre">Books</span> <span class="pre">and</span> <span class="pre">papers</span> <span class="pre">(不断补充中)</span></code></p>
<ul>
<li><p>For Multiagent Systems:</p>
<blockquote>
<div><p><a class="reference external" href="https://github.com/subaruclover/MARL_AI_outline/tree/main/docs/source/_static/references">Multiagent Systems - algorithmic, game-theoretic &amp; logical foundations</a></p>
</div></blockquote>
</li>
</ul>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="usage.html" class="btn btn-neutral float-left" title="强化学习概论" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Qiong.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>